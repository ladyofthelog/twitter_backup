{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "import wget\n",
    "import time\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'USERNAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_name = 'from:'+username\n",
    "\n",
    "# Creating list to append tweet data to\n",
    "tweets_list1 = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "# for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:lumiebre').get_items()):\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search_name).get_items()): #you set the twitter handle name here\n",
    "    tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.media,tweet.retweetedTweet,tweet.quotedTweet])\n",
    "#     if i>maxTweets:\n",
    "#         break\n",
    "#     tweets_list1.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.media,tweet.retweetedTweet,tweet.quotedTweet])\n",
    "\n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df1 = pd.DataFrame(tweets_list1, columns=['Datetime', 'Tweet Id', 'Text', 'Username',\"Media\", \"Retweet\",\"Quote\"])\n",
    "\n",
    "# Display first 5 entries from dataframe\n",
    "tweets_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks to see if there is media in a tweet and if so how many items\n",
    "\n",
    "def photoNum(media):\n",
    "    if media is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds a new column to the data frame containing how many pieces of media are in a tweet\n",
    "\n",
    "tweets_df1[\"Num_Images\"] = tweets_df1[\"Media\"].map(photoNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks for existing \"twitter_backup\" and \"username\" directories in working directory\n",
    "# and creates them if they do not already exist\n",
    "try:\n",
    "    os.mkdir('twitter_backup')\n",
    "    os.chdir('twitter_backup')\n",
    "except:\n",
    "    os.chdir('twitter_backup')\n",
    "try:\n",
    "    os.mkdir(username)\n",
    "    os.chdir(username)\n",
    "except:\n",
    "    os.chdir(username)\n",
    "\n",
    "# saves contents of dataframe to csv  \n",
    "output_file = username+'.csv'\n",
    "tweets_df1[['Datetime', 'Tweet Id', 'Num_Images','Text','Retweet', 'Quote']].to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes images from tweets with photos & thumbnail previews from tweets with videos\n",
    "# and saves them to a file named with the index number in the csv\n",
    "\n",
    "# if your laptop goes to sleep or you need to restart after an error\n",
    "# replacing 0 in the second line with the index number \n",
    "# in the filename of the last image downloaded\n",
    "# i.e. for \"tweed_id87photo0.jpg\" it's 87\n",
    "\n",
    "for index, row in tweets_df1.iterrows():\n",
    "    if row.Media is not None:\n",
    "        if index > 0:\n",
    "            for i in range(len(row.Media)):\n",
    "                img = row.Media[i]\n",
    "                if isinstance(img, sntwitter.Photo):\n",
    "                    url = img.fullUrl\n",
    "                    destination = 'tweet_id{0}photo{1}.jpg'.format(index,i)\n",
    "                    print(destination)\n",
    "                else:\n",
    "                    try:\n",
    "                        url = img.thumbnailUrl\n",
    "                        destination = 'tweet_id{0}mediathumbnail{1}.jpg'.format(index,i)\n",
    "                        wget.download(url, destination)\n",
    "                        print(destination)\n",
    "                    except HTTPError as err:\n",
    "                        print(err.code)\n",
    "                        print(\"timeout... waiting 3 mins and trying again\")\n",
    "                        time.sleep(180)\n",
    "                        continue\n",
    "                    else:\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
